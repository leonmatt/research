{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction Course From NVIDIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is built for GTX 750 TI. Use proper computer capability for your own GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-gencode arch=compute_50,code=sm_50\n"
     ]
    }
   ],
   "source": [
    "cuda_major_version=f\"5\"\n",
    "cuda_minor_version=f\"0\"\n",
    "\n",
    "cc_ver=f\"{cuda_major_version}{cuda_minor_version}\"\n",
    "cuda_args = f\"-gencode arch=compute_{cc_ver},code=sm_{cc_ver}\"\n",
    "print(cuda_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Hello World using CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting add.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile add.cpp\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "\n",
    "// function to add the elements of two arrays\n",
    "void add(int n, float *x, float *y)\n",
    "{\n",
    "  for (int i = 0; i < n; i++)\n",
    "      y[i] = x[i] + y[i];\n",
    "}\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "  int N = 1<<20; // 1M elements\n",
    "\n",
    "  float *x = new float[N];\n",
    "  float *y = new float[N];\n",
    "\n",
    "  // initialize x and y arrays on the host\n",
    "  for (int i = 0; i < N; i++) {\n",
    "    x[i] = 1.0f;\n",
    "    y[i] = 2.0f;\n",
    "  }\n",
    "\n",
    "  // Run kernel on 1M elements on the CPU\n",
    "  add(N, x, y);\n",
    "\n",
    "  // Check for errors (all values should be 3.0f)\n",
    "  float maxError = 0.0f;\n",
    "  for (int i = 0; i < N; i++)\n",
    "    maxError = fmax(maxError, fabs(y[i]-3.0f));\n",
    "  std::cout << \"Max error: \" << maxError << std::endl;\n",
    "\n",
    "  // Free memory\n",
    "  delete [] x;\n",
    "  delete [] y;\n",
    "\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max error: 0\n"
     ]
    }
   ],
   "source": [
    "! g++ add.cpp -o add\n",
    "! ./add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Hello World using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting add.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile add.cu\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "// Kernel function to add the elements of two arrays\n",
    "__global__\n",
    "void add(int n, float *x, float *y)\n",
    "{\n",
    "  for (int i = 0; i < n; i++)\n",
    "    y[i] = x[i] + y[i];\n",
    "}\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "  int N = 1<<20\n",
    " ;\n",
    "  float *x, *y;\n",
    "\n",
    "  // Allocate Unified Memory â€“ accessible from CPU or GPU\n",
    "  cudaMallocManaged(&x, N*sizeof(float));\n",
    "  cudaMallocManaged(&y, N*sizeof(float));\n",
    "\n",
    "  // initialize x and y arrays on the host\n",
    "  for (int i = 0; i < N; i++) {\n",
    "    x[i] = 1.0f;\n",
    "    y[i] = 2.0f;\n",
    "  }\n",
    "\n",
    "  // Run kernel on 1M elements on the GPU\n",
    "  add<<<1, 1>>>(N, x, y);\n",
    "\n",
    "  // Wait for GPU to finish before accessing on host\n",
    "  cudaDeviceSynchronize();\n",
    "\n",
    "  // Check for errors (all values should be 3.0f)\n",
    "  float maxError = 0.0f;\n",
    "  for (int i = 0; i < N; i++)\n",
    "    maxError = fmax(maxError, fabs(y[i]-3.0f));\n",
    "  std::cout << \"Max error: \" << maxError << std::endl;\n",
    "\n",
    "  // Free memory\n",
    "  cudaFree(x);\n",
    "  cudaFree(y);\n",
    "  \n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max error: 0\n"
     ]
    }
   ],
   "source": [
    "! nvcc add.cu -o add_cuda {cuda_args}\n",
    "! ./add_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile the GPU-based Hello World Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==9376== NVPROF is profiling process 9376, command: ./add_cuda\n",
      "Max error: 0\n",
      "==9376== Profiling application: ./add_cuda\n",
      "==9376== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  172.32ms         1  172.32ms  172.32ms  172.32ms  add(int, float*, float*)\n",
      "      API calls:   74.83%  172.32ms         1  172.32ms  172.32ms  172.32ms  cudaDeviceSynchronize\n",
      "                   23.92%  55.086ms         2  27.543ms  352.13us  54.734ms  cudaMallocManaged\n",
      "                    0.74%  1.6996ms         1  1.6996ms  1.6996ms  1.6996ms  cudaLaunchKernel\n",
      "                    0.45%  1.0386ms         2  519.28us  504.34us  534.22us  cudaFree\n",
      "                    0.06%  127.78us       114  1.1200us      77ns  52.862us  cuDeviceGetAttribute\n",
      "                    0.00%  10.833us         1  10.833us  10.833us  10.833us  cuDeviceGetName\n",
      "                    0.00%  6.7190us         1  6.7190us  6.7190us  6.7190us  cuDeviceGetPCIBusId\n",
      "                    0.00%     682ns         3     227ns     120ns     437ns  cuDeviceGetCount\n",
      "                    0.00%     432ns         2     216ns      91ns     341ns  cuDeviceGet\n",
      "                    0.00%     250ns         1     250ns     250ns     250ns  cuModuleGetLoadingMode\n",
      "                    0.00%     188ns         1     188ns     188ns     188ns  cuDeviceTotalMem\n",
      "                    0.00%     154ns         1     154ns     154ns     154ns  cuDeviceGetUuid\n",
      "\n",
      "==9376== Unified Memory profiling result:\n",
      "Device \"NVIDIA GeForce GTX 750 Ti (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "       6  1.3333MB  768.00KB  2.0000MB  8.000000MB  1.436793ms  Host To Device\n",
      "     102  120.47KB  4.0000KB  0.9961MB  12.00000MB  1.976897ms  Device To Host\n",
      "Total CPU Page faults: 51\n"
     ]
    }
   ],
   "source": [
    "! nvprof ./add_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document the GPUs that are in use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jul 19 20:07:31 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.42.06              Driver Version: 555.42.06      CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 750 Ti      Off |   00000000:02:00.0 Off |                  N/A |\n",
      "| 32%   32C    P0              2W /   38W |       2MiB /   2048MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Hello World using GPU with 4 Threads on 1 Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting add_block.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile add_block.cu\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "#include <stdio.h>\n",
    "using namespace std;\n",
    "\n",
    "// Kernel function to add the elements of two arrays\n",
    "__global__\n",
    "void add(int n, float *x, float *y)\n",
    "{\n",
    "  int index = threadIdx.x;\n",
    "  int stride = blockDim.x;\n",
    "  for (int i = index; i < n; i += stride)\n",
    "      y[i] = x[i] + y[i];\n",
    "\n",
    "}\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "  int N = 1<<20;\n",
    "  float *x, *y;\n",
    "\n",
    "  // Allocate Unified Memory â€“ accessible from CPU or GPU\n",
    "  cudaMallocManaged(&x, N*sizeof(float));\n",
    "  cudaMallocManaged(&y, N*sizeof(float));\n",
    "\n",
    "  // initialize x and y arrays on the host\n",
    "  for (int i = 0; i < N; i++) {\n",
    "    x[i] = 1.0f;\n",
    "    y[i] = 2.0f;\n",
    "  }\n",
    "\n",
    "  // Run kernel on 4 * N elements on the GPU\n",
    "  add<<<1, 4>>>(N, x, y);\n",
    "\n",
    "  // Wait for GPU to finish before accessing on host\n",
    "  cudaDeviceSynchronize();\n",
    "\n",
    "  // Check for errors (all values should be 3.0f)\n",
    "  float maxError = 0.0f;\n",
    "  for (int i = 0; i < N; i++)\n",
    "    maxError = fmax(maxError, fabs(y[i]-3.0f));\n",
    "  std::cout << \"Max error: \" << maxError << std::endl;\n",
    "\n",
    "  // Free memory\n",
    "  cudaFree(x);\n",
    "  cudaFree(y);\n",
    "  \n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==9423== NVPROF is profiling process 9423, command: ./add_block\n",
      "Max error: 0\n",
      "==9423== Profiling application: ./add_block\n",
      "==9423== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  59.519ms         1  59.519ms  59.519ms  59.519ms  add(int, float*, float*)\n",
      "      API calls:   51.19%  59.522ms         1  59.522ms  59.522ms  59.522ms  cudaDeviceSynchronize\n",
      "                   46.36%  53.898ms         2  26.949ms  359.68us  53.539ms  cudaMallocManaged\n",
      "                    1.47%  1.7056ms         1  1.7056ms  1.7056ms  1.7056ms  cudaLaunchKernel\n",
      "                    0.85%  994.07us         2  497.04us  488.25us  505.82us  cudaFree\n",
      "                    0.11%  129.97us       114  1.1400us      82ns  53.039us  cuDeviceGetAttribute\n",
      "                    0.01%  9.6370us         1  9.6370us  9.6370us  9.6370us  cuDeviceGetName\n",
      "                    0.01%  7.6550us         1  7.6550us  7.6550us  7.6550us  cuDeviceGetPCIBusId\n",
      "                    0.00%     835ns         3     278ns     127ns     549ns  cuDeviceGetCount\n",
      "                    0.00%     765ns         1     765ns     765ns     765ns  cuDeviceTotalMem\n",
      "                    0.00%     388ns         2     194ns      86ns     302ns  cuDeviceGet\n",
      "                    0.00%     321ns         1     321ns     321ns     321ns  cuModuleGetLoadingMode\n",
      "                    0.00%     174ns         1     174ns     174ns     174ns  cuDeviceGetUuid\n",
      "\n",
      "==9423== Unified Memory profiling result:\n",
      "Device \"NVIDIA GeForce GTX 750 Ti (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "       6  1.3333MB  768.00KB  2.0000MB  8.000000MB  1.449113ms  Host To Device\n",
      "     102  120.47KB  4.0000KB  0.9961MB  12.00000MB  1.987714ms  Device To Host\n",
      "Total CPU Page faults: 51\n"
     ]
    }
   ],
   "source": [
    "! nvcc add_block.cu -o add_block {cuda_args}\n",
    "! nvprof ./add_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Hello World using GPU with 256 Threads on multiple Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting add_grid.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile add_grid.cu\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "// Kernel function to add the elements of two arrays\n",
    "__global__\n",
    "void add(int n, float *x, float *y)\n",
    "{\n",
    "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "  int stride = blockDim.x * gridDim.x;\n",
    "  for (int i = index; i < n; i += stride)\n",
    "    y[i] = x[i] + y[i];\n",
    "\n",
    "}\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "  int N = 1<<20;\n",
    "  float *x, *y;\n",
    "\n",
    "  // Allocate Unified Memory â€“ accessible from CPU or GPU\n",
    "  cudaMallocManaged(&x, N*sizeof(float));\n",
    "  cudaMallocManaged(&y, N*sizeof(float));\n",
    "\n",
    "  // initialize x and y arrays on the host\n",
    "  for (int i = 0; i < N; i++) {\n",
    "    x[i] = 1.0f;\n",
    "    y[i] = 2.0f;\n",
    "  }\n",
    "\n",
    "  // Run kernel on 1M elements on the GPU\n",
    "  int blockSize = 256;\n",
    "  //int numBlocks = (N + blockSize - 1) / blockSize;\n",
    "  int numBlocks = 256;\n",
    "\n",
    "  cout << \"N is: \" << N << endl << \"numBlocks is: \" << numBlocks << endl;\n",
    "\n",
    "  add<<<numBlocks, blockSize>>>(N, x, y);\n",
    "\n",
    "  // Wait for GPU to finish before accessing on host\n",
    "  cudaDeviceSynchronize();\n",
    "\n",
    "  // Check for errors (all values should be 3.0f)\n",
    "  float maxError = 0.0f;\n",
    "  for (int i = 0; i < N; i++)\n",
    "    maxError = fmax(maxError, fabs(y[i]-3.0f));\n",
    "  std::cout << \"Max error: \" << maxError << std::endl;\n",
    "\n",
    "  // Free memory\n",
    "  cudaFree(x);\n",
    "  cudaFree(y);\n",
    "  \n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N is: 1048576\n",
      "numBlocks is: 256\n",
      "Max error: 0\n",
      "==9474== NVPROF is profiling process 9474, command: ./add_grid\n",
      "N is: 1048576\n",
      "numBlocks is: 256\n",
      "Max error: 0\n",
      "==9474== Profiling application: ./add_grid\n",
      "==9474== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  167.91us         1  167.91us  167.91us  167.91us  add(int, float*, float*)\n",
      "      API calls:   92.04%  54.803ms         2  27.402ms  528.19us  54.275ms  cudaMallocManaged\n",
      "                    4.97%  2.9589ms         1  2.9589ms  2.9589ms  2.9589ms  cudaLaunchKernel\n",
      "                    2.43%  1.4483ms         2  724.16us  687.21us  761.11us  cudaFree\n",
      "                    0.29%  171.38us         1  171.38us  171.38us  171.38us  cudaDeviceSynchronize\n",
      "                    0.24%  143.07us       114  1.2550us      85ns  62.578us  cuDeviceGetAttribute\n",
      "                    0.02%  10.671us         1  10.671us  10.671us  10.671us  cuDeviceGetName\n",
      "                    0.01%  7.8300us         1  7.8300us  7.8300us  7.8300us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.0590us         3     353ns     112ns     780ns  cuDeviceGetCount\n",
      "                    0.00%     459ns         2     229ns      89ns     370ns  cuDeviceGet\n",
      "                    0.00%     357ns         1     357ns     357ns     357ns  cuDeviceTotalMem\n",
      "                    0.00%     303ns         1     303ns     303ns     303ns  cuModuleGetLoadingMode\n",
      "                    0.00%     208ns         1     208ns     208ns     208ns  cuDeviceGetUuid\n",
      "\n",
      "==9474== Unified Memory profiling result:\n",
      "Device \"NVIDIA GeForce GTX 750 Ti (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "       6  1.3333MB  768.00KB  2.0000MB  8.000000MB  1.417047ms  Host To Device\n",
      "     102  120.47KB  4.0000KB  0.9961MB  12.00000MB  2.596555ms  Device To Host\n",
      "Total CPU Page faults: 51\n"
     ]
    }
   ],
   "source": [
    "! nvcc add_grid.cu -o add_grid {cuda_args}\n",
    "! ./add_grid\n",
    "! nvprof ./add_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove files that are no longer needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm add*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
